#!/usr/bin/env python3
"""
Extrai as sÃ©ries histÃ³ricas da TAEG e da TAN para novos crÃ©ditos Ã  habitaÃ§Ã£o
e grava em ficheiros CSV separados na pasta correta.
Inclui diagnÃ³stico para detetar nomes corretos das mÃ©tricas disponÃ­veis.
"""
from pathlib import Path
import pandas as pd
from pyjstat import pyjstat

# --- ConfiguraÃ§Ã£o ---
DOMAIN_ID  = 21
DATASET_ID = "5e42e78146bb44759188678266b04c4e"
BPSTAT_API_URL = "https://bpstat.bportugal.pt/data/v1"

# Caminho de saÃ­da para: packages/webapp/public/data
OUT_DIR = Path(__file__).resolve().parents[2] / "webapp" / "public" / "data"

# Nomes das colunas
COL_FINALIDADE = 'Finalidade'
COL_TIPO_OPERACAO = 'Tipo de informaÃ§Ã£o'
COL_METRICA = 'MÃ©trica'

SERIES_TO_FETCH = {
    "interest_rate_taeg": {"filter": "Taxa anual de encargos efetiva global"},
    "interest_rate_tan":  {"filter": "Taxa acordada anualizada"}
}

def fetch_full_dataset() -> pd.DataFrame:
    url = f"{BPSTAT_API_URL}/domains/{DOMAIN_ID}/datasets/{DATASET_ID}/?lang=PT"
    print(f"-> A buscar dataset de Taxas de Juro...")
    dataset = pyjstat.Dataset.read(url, timeout=90)
    df = dataset.write('dataframe')
    print("   âœ… Dataset carregado.")
    return df

def diagnosticar_metricas(df: pd.DataFrame):
    print("\nğŸ“Š ComposiÃ§Ãµes Ãºnicas de Finalidade / Tipo / MÃ©trica no dataset filtrado:")
    unique_rows = df[[COL_FINALIDADE, COL_TIPO_OPERACAO, COL_METRICA]].drop_duplicates()
    for _, row in unique_rows.iterrows():
        print(f" - Finalidade: {row[COL_FINALIDADE]} | Tipo: {row[COL_TIPO_OPERACAO]} | MÃ©trica: {row[COL_METRICA]}")

def main():
    try:
        df = fetch_full_dataset()
        if df.empty:
            raise ValueError("DataFrame vazio.")

        base_filtered_df = df[
            (df[COL_FINALIDADE] == "HabitaÃ§Ã£o") &
            (df[COL_TIPO_OPERACAO] == "Novas operaÃ§Ãµes")
        ].copy()
        
        print(f"   âœ… Encontrados {len(base_filtered_df)} registos de Novas OperaÃ§Ãµes de HabitaÃ§Ã£o.")

        diagnosticar_metricas(base_filtered_df)
        OUT_DIR.mkdir(parents=True, exist_ok=True)

        for series_key, details in SERIES_TO_FETCH.items():
            print(f"\n   -> A processar sÃ©rie: {series_key}")
            
            filter_string = details['filter'].strip()
            series_df = base_filtered_df[base_filtered_df[COL_METRICA].str.strip() == filter_string]

            print(f"      ğŸ” Registos totais antes do dropna: {len(series_df)}")
            if series_df.empty:
                print(f"      âŒ Nenhum dado encontrado para: '{filter_string}'")
                continue

            print("      ğŸ” Amostra dos dados da sÃ©rie TAN:")
            print(series_df.head(10).to_string())
            print(series_df.columns)

            output_df = (
                series_df[['Data', 'value']]
                .dropna(subset=['value'])
                .rename(columns={"Data": "date", "value": "value"})
                .sort_values("date")
            )

            print(f"      ğŸ“‰ Registos com valor apÃ³s dropna: {len(output_df)}")
            if output_df.empty:
                print(f"      âš ï¸ Todos os valores sÃ£o nulos ou nÃ£o numÃ©ricos. Ficheiro nÃ£o serÃ¡ gravado.")
                continue

            output_df['date'] = pd.to_datetime(output_df['date']).dt.strftime('%Y-%m-%d')
            outfile_path = OUT_DIR / f"{series_key}.csv"
            output_df.to_csv(outfile_path, index=False)
            print(f"      âœ… Gravado {len(output_df)} linhas em {outfile_path.name}")

        print(f"\nğŸ Ficheiros gravados em: {OUT_DIR.resolve()}")

    except Exception as e:
        print(f"\nâŒ Erro fatal no script de taxas de juro: {e}")

if __name__ == "__main__":
    main()
